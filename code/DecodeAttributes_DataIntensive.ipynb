{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"sample_app\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext (sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"inferSchema\", \"true\").option(\"delimiter\", \"\\u0001\").load(\"hdfs:///user/pknees/RSC20/training.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+--------------------+----+----+----+--------+--------------------+----------+--------------------+----+----+-----+----------+--------------------+----+----+-----+----------+-----+----+----+----+----+\n",
      "|                 _c0| _c1|                 _c2| _c3| _c4| _c5|     _c6|                 _c7|       _c8|                 _c9|_c10|_c11| _c12|      _c13|                _c14|_c15|_c16| _c17|      _c18| _c19|_c20|_c21|_c22|_c23|\n",
      "+--------------------+----+--------------------+----+----+----+--------+--------------------+----------+--------------------+----+----+-----+----------+--------------------+----+----+-----+----------+-----+----+----+----+----+\n",
      "|101\t1942\t18628\t15...|null|E7D6C5094767223F6...|null|null|null|TopLevel|22C448FF81263D4BA...|1581262691|D557B03872EF8986F...| 986|1201|false|1274269909|00000776B07587ECA...|  94| 648|false|1478011810|false|null|null|null|null|\n",
      "+--------------------+----+--------------------+----+----+----+--------+--------------------+----------+--------------------+----+----+-----+----------+--------------------+----+----+-----+----------+-----+----+----+----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segments.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"text_tokens\", \"hashtags\", \"tweet_id\", \"present_media\", \"present_links\", \"present_domains\",\n",
    "                \"tweet_type\", \"language\", \"tweet_timestamp\", \"engaged_with_user_id\", \"engaged_with_user_follower_count\",\n",
    "               \"engaged_with_user_following_count\", \"engaged_with_user_is_verified\", \"engaged_with_user_account_creation\",\n",
    "               \"engaging_user_id\", \"engaging_user_follower_count\", \"engaging_user_following_count\", \"engaging_user_is_verified\",\n",
    "               \"engaging_user_account_creation\", \"engaged_follows_engaging\", \"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segments.toDF(*column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced = segments\n",
    "big,reduced = segments.randomSplit([0.999, 0.001], seed = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+------------------------------+--------------+\n",
      "|reply_timestamp|retweet_timestamp|retweet_with_comment_timestamp|like_timestamp|\n",
      "+---------------+-----------------+------------------------------+--------------+\n",
      "|           null|             null|                          null|    1581412148|\n",
      "|           null|             null|                          null|    1581348656|\n",
      "|           null|             null|                          null|          null|\n",
      "|           null|             null|                          null|          null|\n",
      "|           null|             null|                          null|    1581059560|\n",
      "+---------------+-----------------+------------------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced.select(\"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 15:58:00.392180 140458577397568 file_utils.py:41] PyTorch version 1.0.1.post2 available.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "#f.col(reduced.select(\"text_tokens\")).apply(lambda text_tokens: \"\".join(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(text_tokens.split('\\t')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text_tokens: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.select(\"text_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode list[] columns to boolean whether is it contain elements or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsElement(inp):\n",
    "    try:\n",
    "        if len(inp) > 0:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "encodeToBool = udf(lambda inp: containsElement(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the list elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countElements(inp,boolCol):\n",
    "    if boolCol == 'true':        \n",
    "        return len(inp.split())    \n",
    "    \n",
    "    return 0\n",
    "\n",
    "elementCount = udf(lambda inp,bl: countElements(inp,bl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the media type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countMedia(inp,boolCol, mediaType):\n",
    "    if boolCol == 'true':\n",
    "        return inp.split().count(str(mediaType))\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to define number of videos, photos, and GIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaPhoto = udf(lambda inp,bl: countMedia(inp, bl, \"Photo\"))\n",
    "mediaGif = udf(lambda inp,bl: countMedia(inp, bl, \"GIF\"))\n",
    "mediaVideo = udf(lambda inp,bl: countMedia(inp, bl, \"Video\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that is there other media just for sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countOther(inputCol, boolCol, video, gif, photo):\n",
    "    if boolCol == \"true\":\n",
    "        numInCol = len(inputCol.split())\n",
    "        mediaNum = int(video) + int(gif) + int(photo)\n",
    "        if mediaNum == numInCol:\n",
    "            return 0        \n",
    "        return numInCol-mediaNum  \n",
    "    return 0    \n",
    "\n",
    "mediaOther = udf(lambda inp,bl,vd,gf,ph: countOther(inp,bl,vd,gf,ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyLabels(inputCol):\n",
    "    if inputCol is not None:\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "labelClassify = udf(lambda inp: classifyLabels(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode 'present_media' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"has_media\",encodeToBool(f.col(\"present_media\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|has_media|present_media|\n",
      "+---------+-------------+\n",
      "|     true|        Photo|\n",
      "|     true|        Video|\n",
      "|     true|        Video|\n",
      "|     true|        Photo|\n",
      "|     true|        Video|\n",
      "|     true|        Photo|\n",
      "|    false|         null|\n",
      "+---------+-------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced.select(\"has_media\", \"present_media\").show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the media types for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"no_Photo\",mediaPhoto(f.col(\"present_media\"),f.col(\"has_media\")))\n",
    "reduced = reduced.withColumn(\"no_Gif\",mediaGif(f.col(\"present_media\"),f.col(\"has_media\")))\n",
    "reduced = reduced.withColumn(\"no_Video\",mediaVideo(f.col(\"present_media\"),f.col(\"has_media\")))\n",
    "reduced = reduced.withColumn(\"no_Other\",mediaOther(f.col(\"present_media\"),f.col(\"has_media\"),f.col(\"no_Video\"),f.col(\"no_Gif\"),f.col(\"no_Photo\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"has_media\", \"present_media\", \"no_Media\").show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"has_media\", \"present_media\", \"no_Video\", \"no_Gif\",\"no_Photo\",\"no_Other\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"has_media\", \"present_media\", \"no_Video\", \"no_Gif\",\"no_Photo\",\"no_Other\").filter(reduced[\"has_media\"] == \"true\").show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"has_links\",encodeToBool(f.col(\"present_links\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"no_links\",elementCount(f.col(\"present_links\"),f.col(\"has_links\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"present_links\", \"has_links\", \"no_links\").filter(reduced[\"has_links\"] == \"true\").filter(reduced[\"no_links\"] != 1).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"has_hashtags\",encodeToBool(f.col(\"hashtags\")))\n",
    "reduced = reduced.withColumn(\"no_hashtags\",elementCount(f.col(\"hashtags\"),f.col(\"has_hashtags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------+\n",
      "|            hashtags|has_hashtags|no_hashtags|\n",
      "+--------------------+------------+-----------+\n",
      "|221D4221C80D250DB...|        true|          1|\n",
      "|                null|       false|          0|\n",
      "|E5B60323EDA9808E7...|        true|          2|\n",
      "|D680643EDEC162480...|        true|          2|\n",
      "|                null|       false|          0|\n",
      "|                null|       false|          0|\n",
      "|                null|       false|          0|\n",
      "+--------------------+------------+-----------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced.select(\"hashtags\", \"has_hashtags\", \"no_hashtags\").show(7)\n",
    "#.filter(reduced[\"has_links\"] == \"true\").filter(reduced[\"no_domains\"] != 1).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"has_domains\",encodeToBool(f.col(\"present_domains\")))\n",
    "reduced = reduced.withColumn(\"no_domains\",elementCount(f.col(\"present_domains\"),f.col(\"has_domains\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+----------+\n",
      "|     present_domains|has_domains|no_domains|\n",
      "+--------------------+-----------+----------+\n",
      "|                null|      false|         0|\n",
      "|                null|      false|         0|\n",
      "|                null|      false|         0|\n",
      "|                null|      false|         0|\n",
      "|                null|      false|         0|\n",
      "|3183ACF54B4022B25...|       true|         1|\n",
      "|                null|      false|         0|\n",
      "+--------------------+-----------+----------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced.select(\"present_domains\", \"has_domains\", \"no_domains\").show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify dependent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"is_reply\",labelClassify(f.col(\"reply_timestamp\"))).withColumn(\"is_retweet\",labelClassify(f.col(\"retweet_timestamp\"))).withColumn(\"is_retweet_with_comment\",labelClassify(f.col(\"retweet_with_comment_timestamp\"))).withColumn(\"is_like\",labelClassify(f.col(\"like_timestamp\")))\n",
    "        \n",
    "    \n",
    "#\"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"reply_timestamp\", \"is_reply\", \"retweet_timestamp\", \"is_retweet\", \"retweet_with_comment_timestamp\", \"is_retweet_with_comment\", \"like_timestamp\", \"is_like\").show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"is_reply\",\"is_retweet\", \"is_retweet_with_comment\", \"is_like\",\"has_links\", \"no_links\", \"has_hashtags\", \"no_hashtags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode tokens just for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "transf = udf(lambda text_tokens: \"\".join(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(text_tokens.split('\\t')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "'''\n",
    "def convertTimesTamp(input):\n",
    "    converted = 0\n",
    "    try:\n",
    "        converted = datetime.fromtimestamp(input).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        converted = null\n",
    "    return str(converted)\n",
    "'''\n",
    "#timestampImport = udf(lambda ts:convertTimesTamp(ts))\n",
    "#timestampImport = udf(lambda ts:datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "timestampImport = udf(lambda ts:datetime.fromtimestamp(ts).strftime('%d'))\n",
    "    #lambda: datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcWeekDay =  udf(lambda x: datetime.strptime(x, '%Y-%m-%d').strftime('%w').substr(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"decoded_tweet_text\",transf(f.col(\"text_tokens\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = reduced.withColumn(\"tweet_timestamp_decoded\",timestampImport(f.col(\"tweet_timestamp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segments.withColumn(\"tweet_timestamp_decoded\",timestampImport(f.col(\"tweet_timestamp\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counter = 0\n",
    "if((\"media_type\").length > 0 ):\n",
    "    return True # Contains media\n",
    "else return False # Doesn't contain media \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"text_tokens\",\"decoded_tweet_text\", \"tweet_type\", \"tweet_id\", \"reply_timestamp\", \"retweet_timestamp\", \"retweet_with_comment_timestamp\", \"like_timestamp\").show(1,False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.select(\"tweet_timestamp_decoded\").show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.select(\"tweet_timestamp_decoded\").show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tweet_timestamp_decoded='07'),\n",
       " Row(tweet_timestamp_decoded='11'),\n",
       " Row(tweet_timestamp_decoded='09'),\n",
       " Row(tweet_timestamp_decoded='08'),\n",
       " Row(tweet_timestamp_decoded='06'),\n",
       " Row(tweet_timestamp_decoded='10'),\n",
       " Row(tweet_timestamp_decoded='12'),\n",
       " Row(tweet_timestamp_decoded='13')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.select(\"tweet_timestamp_decoded\").distinct().rdd.map(lambda r:  r).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.select(\"tweet_timestamp_decoded\").rdd.max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-02-06 01:00:00'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.select(\"tweet_timestamp_decoded\").rdd.min()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for the 6th of February, only use verified users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentsFiltered = segments.filter(segments[\"tweet_timestamp_decoded\"] == \"06\" ).filter(segments['engaged_with_user_is_verified'] == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentsFiltered = segments.filter(segments[\"tweet_timestamp_decoded\"] == \"12\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentsFiltered.select(\"tweet_timestamp_decoded\").rdd.max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentsFiltered.select(\"tweet_timestamp_decoded\").rdd.min()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4422804"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentsFiltered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121386431"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036435736379793554"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentsFiltered.count()/segments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reduced.filter($\"tweet_timestamp\" ===  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
